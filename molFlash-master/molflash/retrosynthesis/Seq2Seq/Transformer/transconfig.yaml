config:
  type: retrosynthesis
  modelName: Transformer
  filePath: ['/home/bayeslabs/molFlash/molflash/generator/Seq2Seq/train_500.csv','/home/bayeslabs/molFlash/molflash/generator/Seq2Seq/train_500.csv']
  preprocessing: input_data
  loss_fn: nn.CrossEntropyLoss(ignore_index = dm.source_vocab['<pad>'])
  metrics: F1(num_classes = len(dm.target_vocab),mdmc_average='samplewise')
  batch_size: 16
  epochs: 10
  gpus: 1
  logger:
  optimizer: optim.Adam
  learning_rate: 0.001

  encoder_hid_dim: 256
  decoder_hid_dim: 256
  encoder_ff_dim: 512
  decoder_ff_dim: 512
  encoder_num_layers: 4
  decoder_num_layers: 4
  encoder_nheads: 8
  decoder_nheads: 8

  encoder_dropout: 0.1
  decoder_dropout: 0.1
  split: [0.8,0.1,0.1]

  
