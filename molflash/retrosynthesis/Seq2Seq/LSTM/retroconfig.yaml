config:
  type: retrosynthesis
  modelName: LSTM
  filePath: ['/home/bayeslabs/molFlash/molflash/generator/Seq2Seq/train_500.csv', '/home/bayeslabs/molFlash/molflash/generator/Seq2Seq/train_500.csv']
  preprocessing: input_data
  loss_fn: nn.CrossEntropyLoss()
  metrics: F1(num_classes = len(dm.target_vocab),mdmc_average='samplewise')

  batch_size: 32
  epochs: 5
  splits: [0.8,0.1,0.1]
  gpus: 1
  logger:
  optimizer: optim.Adam
  learning_rate: 0.01

  enc_emb_size: 300
  enc_hid_size: 1024
  enc_n_layers: 2
  enc_drop: 0.1

  dec_emb_size: 300
  dec_hid_size: 1024
  dec_n_layers: 2
  dec_drop: 0.1
  
